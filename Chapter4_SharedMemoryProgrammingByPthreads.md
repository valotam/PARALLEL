# Pthreads를 이용한 공유 메모리 프로그래밍

개발자 입장에서 보면 공유 메모리 시스템은 모든 코어가 모든 메모리 위치를 액세스할 수 있다고 가정한 상태로 작업을 한다.
따라서 코어에서 해야 할 작업을 조율하는 문제의 명백한 접근 방법은 특정 메모리 위치를 "공유"하도록 설정하는 것이다. 이것은 병렬 프로그램밍에서 당연한 방법이다.
실제로 모든 병렬 프로그램이 공유 메모리 방법을 사용할 필요가 있을까? 이번에는 공유 메모리 시스템에서 프로그래밍할 때 문제가 있다는 것에 대해 배우게 될 것이다. 그러한 문제점은 분산 메모리 시스템과는 다르다.

예를 들어, 다른 코어들이 하나의 공유 메모리 위치를 업데이트하려고 하면 공유 위치의 내용은 예측 불가능하다는 것을 안다.(불확실성, 캐쉬 일관성 오류, 거짓 공유)
공유 위치를 업데이트하는 코드는 **critical section** 의 한 예이다. 크리티컬 섹션의 다른 예들을 살펴보고 크리티컬 섹션에 대한 액세스를 제어하는 몇 가지 방법에 대해 배워 보자.

> 배울 내용

-   thread: 하나의 프로세서에서 동작하는 프로그램의 인스턴스 (분산에서는 process)
-   ~~sleep: 각 스레드들이 다른 스레드가 어떤 작업을 끝날 때까지 코드 블록의 실행을 기다리도록 하기 위해 스레들 간에 동기화 하는 법~~
-   ~~fine-tune: 크리티컬 섹션이 매우 큰 경우에 대한 액세스 환경 중 하나~~
-   the usage of cash memories to slow down shared memory program
-   stay: 연속된 호출 사이에 "상태 유지"가 올바른 결과를 얻지 못하도록 하는 함수에 대한 고찰

## Process, thread, and pthreads

**실행 파일의 구조**

-   스택을 위한 메모리 블록
-   힙을 위한 메모리 블록
-   프로세스에 할당된 시스템의 리소스 descriptor, 예를 들면 파일 디스크립터가 이에 해당한다.
-   프로세스가 액세스할 수 있는 하드웨어와 소프트웨어 리소스에 대한 정보인 보안 정보
-   프로세스가 실행할 준비가 됐는지 리소스를 기다리는지에 대한 프로세스의 상태 정보, 프로그램 카운터를 포함한 레지스터의 내용 등이다.

기본적으로 대부분의 시스템에서 프로세스의 메모리 블록은 private이다. 다른 프로세스가 운영체제가 간섭하지 않는 프로세스의 메모리를 액세스할 수 없다.
그러나 공유 메모리 프로그램을 사용할 때, 공유 메모리의 "프로세스"는 다른 메모리를 더욱 쉽게 액세스할 수 있도록 해 준다. 실제로, 스택이나 프로그램 카운터를 제외하고는 프로세스의 특정한 정보를 비롯한 거의 모든 것을 공유할 수 있다.

### 스레드의 시작

MPI 프로그램과 달리 프로세스는 스크립트에 의해 시작된다. Pthreads에서 스레드는 프로그램 실행 파일에 의해 실행된다.

스레드를 명시적으로 시작하기 위한 코드를 추가해야 하고 스레드에 정보를 저장하기 위한 자료 구조(`pthread_t`)가 필요하다.

`pthread_t` 객체는 [opaque](https://en.wikipedia.org/wiki/Opaque_data_type)(저장하는 실제 데이터는 시스템 고유의 정보이며 그 안에 데이터 멤버는 사용자 코드에 의해 직접 액세스할 수는 없는 데이터 구조)이다. Pthreads 표준은 pthread_t 객체가 관련 있는 객체를 식별할 수 있도록 하는 충분한 정보를 저장한다는 것을 보장한다. 따라서 스레드와 관련된 pthread_t 객체를 추출하기 위해 사용되는 Pthreads 함수가 있다. 그리고 두 개의 스레드가 관련된 같은 pthread_t 객체를 사용하고 있는지 여부를 결정하는 Pthreads 함수도 있다.

스레드를 시작하기 위한 `pthread_create` 함수를 사용한다.

```c
int pthread_create(
      pthread_t*              thread_p                  /* out */,
      const pthread_attr_t*   attr_p                    /* in  */,
      void*                   (*start_routine)(void*)   /* in  */,
      void*                   arg_p                     /* in  */);
```

첫 번째 인수는 적절한 pthread_t 객체의 포인터이다. 객체는 pthread_create에 대한 호출로 인해 할당되는 것은 아니라, pthread_create 호출 전에 할당되어 있어야 한다.
두 번째 인수는 사용하지 않는데 위의 함수 호출에서는 NULL을 넘기면 된다.
세 번째 인수는 스레드가 실행하는 함수이며 마지막 함수는 함수 시작 루틴에 전달해야 하는 인수들의 포인터이다.

대부분의 Pthreads 함수의 리턴값은 함수 호출에 에러가 있는지를 알려 준다.
마지막 두 개의 인수를 보면, pthread_create에 의해 시작된 함수는 다음과 같은 프로토 타입을 가져야만 한다.

```c
void* thread_functrion(void* args_p);
```

void* 타입은 C에서 어떤 포인터 타입으로도 형변환이 된다는 점을 기억하자. 따라서 args_p는 스레드 함수에서 필요한 하나 이상의 값을 포함하는 리스트를 가리킨다.
이를 통해 각 스레드에 유니크한 정수형 rank를 효과적으로 할당한다. 이러한 작업이 필요한 이유는 다음의 문제를 고려해 보자.
두 개의 스레드로 구성된 Pthreads 프로그램을 시작하는데 스레드 중 하나의 스레드에서 에러가 발생했다. 사용자 입장에서는 어떤 스레드에서 에러가 발생했는지 어떻게 알 수 있을까? pthread_t 객체는 opaque이기 때문에 출력할 수 없다. 그러나 스레드를 시작할 때 첫 번째 스레드의 랭크를 0, 두 번째 스레드의 랭크를 1로 설정하면, 에러 메시지에 스레드의 랭크를 포함시키면 어떤 스레드가 실행할 때 문제가 발생했는지 쉽게 알 수 있다.

### 스레드의 실행

main 함수를 실행하는 스레드는 보통 main thread라고 한다.

Pthreads에서 개발자는 스레드가 어디에서 실행될지 직접 제어할 수는 없다.(리눅스에서는 가능하지만 이식성이 떨어지는 프로그램이 된다.)

pthread_create에는 어떤 코어에서 어떤 스레드가 실행되어야 하는지를 설정하는 인수는 없다. 스레드의 배치는 운영체제에 의해 제어된다. 실제로 헤비 로드 시스템에서는 실행된 스레드가 모두 같은 코어에 실행될 수도 있다. 사실 프로그램에서 코어보다 더 많은 스레드를 갖고 실행한다면 하나의 코어에 여러 개의 스레드가 실행될 수밖에 없다. 그러나 사용되고 있지 않은 코어가 있다면 운영체제는 일반적으로 새로운 스레드를 사용되고 있지 않은 코어에 배치하게 된다.

### 스레드의 중지

pthread_join이 한 번 호출하면 pthread_t 객체와 연결된 스레드를 대기한다. pthread_join의 문법적 형식은 다음과 같다.

```c
int pthread_join(
      pthread_t  thread         /* in   */,
      void**     ret_val_p      /* out  */);
```

두 번째 인수는 스레드에 연산된 리턴 값을 받는데 사용된다. 우리의 예제에서는 각 스레드는 return을 실행하고 결국 메인 스레드는 pthread_join을 호출하여 스레드가 완전히 종료될 수 있도록 한다.

### 에러 체킹

### 스레드의 시작에 대한 다른 접근

프로그램이 시작할 때 필요한 모든 스레드를 동시 생성하고 다른 스레드가 종료할 때까지 기다리는 방법 말고도,
필요할 때마다 스레드를 생성하고 조인하는 방식이 있다. 하지만 스레드를 시작할 때 필요한 시간은 부동소수점 연산 오퍼레이션보다 크기 때문에 어플리케이션에서 "필요한 스레드의 시작"의 최대 성능은 이상적이지 않다. 그런 경우에, 다소 복잡한 방법을 사용하는 것이 맞다. 그러한 복잡한 방법은 이 두 가지 방법의 특성을 갖고 있다. 메인 스레드는 프로그램의 시작할 때 필요한 내용을 기대하며 시작한다. 그러나 스레드가 종료하지는 않았지만 작업을 하지 않는 경우 더 많은 작업이 사용 가능해질 때까지 아이들 상태가 된다.

## 매트릭스-벡터 곱셈

$$
y_i = \sum^{n-1}_{j=0} a_{ij}x_j
$$

```c {.line-numbers}
for(i = 0; i < m; i++) {
  y[i] = 0.0;
  for (j = 0; j < n; j++) {
    y[i] += A[i][j]*x[j];
  }
}
```

위의 코드를 스레드별로 해야 할 작업으로 분할하여 병렬화 하려고 한다. 한 가지 가능성은 바깥쪽 루프를 스레드별로 분할하는 것이다.

그러면 하나의 스레드는 A의 i행의 모든 항목과 x의 모든 항목을 액세스한다. 각 스레드가 A에 할당된 행과 y에 할당된 컴포넌트를 액세스하는 반면에 각 스레드는 x의 모든 컴포넌트를 액세스해야 한다. 이것은 x가 공유된다는 것을 의미한다.

## 크리티컬 섹션

매트릭스-벡터 연산은 공유 메모리 위치가 쉽게 액세스가 가능하기 때문에 코드를 작성하기가 쉽다. 초기화 후에 y를 제외한 모든 변수는 스레드에서 쉽게 읽어 올 수 있다. y를 제외하고는 공유 변수는 메인 스레드에서 초기화된 후에 변경될 수 없다. 나아가 스레드들이 y에 대해 뭔가를 변경하려 한다고 하더라도 오직 하나의 스레드만이 개별적인 컴포넌트를 변경할 수 있다. 따라서 두 개(혹은 그 이상)의 스레드들이 하나의 컴포넌트를 변경하려는 시도를 하지 않는다. 그렇다면 하나의 메모리 위치에 여러 개의 스레드가 업데이트하려는 경우에는 어떤 일이 발생할까?
아래 코드를 실행해보자.

```c
y = Compute(my_rank); /* y = my_rank + 1; */
x = x + y;
```

| 시간  | 스레드 0  | 스레드 1
--|---|--
| 1 | 메인 스레드에서 시작  |  
| 2 | Compute() 호출  | 메인 스레드에서 시작
| 3 | y = 1 할당  | Compute() 호출
| 4 | x = 0과 y = 1을 레지스터에 넣음 | y = 2 할당
| 5 | 0과 1을 덧셈  | x = 0과 y = 2를 레지스터에 넣음
| 6 | 1을 메모리 위치 x에 저장  | 0과 2를 덧셈
| 7 |   | 1을 메모리 위치 x에 저장

스레드 0이 결과를 저장하기 전에 스레드 1이 메인 메모리에서 레지스터로 x를 복사한면, 스레드 0에 의해 실행된 연산은 스레드 1에 의해 덮어쓰게 된다. 혹은 스레드 1이 스레드 0보다 먼저 실행되면 결과는 스레드 0에 의해 덮어쓰이게 된다. 사실 어떤 스레드라도 메모리로부터 x를 읽기 전에 결과를 저장하지 않으면 "승자"의 결과는 "패자"의 결과에 의해 덮어쓰이게 된다. 이 문제는 다중 스레드가 하나의 공유 리소스를 업데이트하려고 할 때 발생한다. 이 경우에 공유 변수에는 어떤 결과각 저장될지 예측할 수 없다. 이런 경우가 **race condition** 이다. 올바른 결과를 얻기 위해 스레드 중 하나는 `x = x + y`를 실행하도록 보장해야 한다. 이 문장은 다른 스레드가 문장을 실행하기 전에 문장의 실행을 끝낸다. 따라서 이 문장이 **critical section** 이며, 한 번에 하나의 스레드에 의해서만 업데이트될 수 있는 공유 리소스를 업데이트하는 코드의 블럭이다.

## 비지-웨이팅

스레드 0이 크리티컬 섹션을 실행하려고 하면, 스레드 1은 아직 문장을 실행하지 않았다는 것을 보장해야 한다. 스레드 0이 문장을 실행하면 스레드 1은 스레드 0이 문장을 실행하는 것을 결정하도록 한다. 따라서 스레드 1은 스레드 0이 완료될 때까지 문장 실행을 시도하지 않는다. 마지막으로 스레드 0은 문장 실행이 완료된 후에 스레드 1이 스레드 0이 완료됐다는 것을 결정하는 방법을 제공해야 한다. 따라서 스레드 1은 문장을 안전하게 실행하게 된다.

이것을 가능하게 하는 간단한 방법은 "flag" 변수를 사용하는 것이다. "flag"는 메인 스레드에서 0으로 설정하는 공유 int 이며 다음과 같이 활용할 수 있다.

```c
y = Compute(my_rank); /* y = my_rank + 1; */
while (flag != my_rank) {};
x = x + y;
flag++;
```

while문이 비어 있는 다소 특별한 속성은 위 설명을 이해하였다면 자연스러울 것이다.
이 while loop이 busy-waiting의 예이다. 비지-웨이팅에서 스레드는 반복해서 조건을 테스트하지만 컨디션이 적절한 값을 가질 때까지 별다른 작업을 하지 않는다.

하지만 컴파일러 최적화가 동작하면 컴파일러는 비지-웨이팅이 올바르게 동작하지 못하도록 변경할 수도 있다. 이유는 컴파일러가 프로그램이 멀티스레딩인지 알지 못하기 때문이다. 따라서 변수 x와 flag는 다른 스레드에 의해 수정될 수 있다는 것을 알지 못한다. 예를 들어 최적화 컴파일러는 프로그램의 문장 순서가 바뀌더라도 레지스터를 잘 사용할 수 있도록 한다. 그래서 코드가 아래와 같이 변할 수도 있다.

```c
y = Compute(my_rank); /* y = my_rank + 1; */
x = x + y;
while (flag != my_rank) {};
flag++;
```

이것은 비지-웨이팅 루프를 거스르는 코드이다. 그래서 비지-웨이팅은 크리티컬 섹션에 대한 액세스를 제어할 때 발생하는 문제점을 해결하기 위해 최적의 솔루션이 아니라는 사실을 알 수 있다.

## 뮤텍스

비지-웨이팅을 사용하는 스레드는 계속 CPU를 사용하기 때문에 비지-웨이팅은 일반적으로 크리티컬 섹션에 대한 액세스를 제한하는 문제의 올바른 솔루션이 아니다. 더 나은 두 개의 솔루션이 존재하며 하나는 mutex이고 다른 하나는 semaphore다. 뮤텍스는 mutual exclusion의 축약어이며, 뮤텍스는 변수의 특수한 타입이고 특별한 여러 개의 함수를 함께 사용한다. 뮤텍스는 한 번에 하나의 스레드가 크리티컬 섹션을 액세스하도록 제한하는 데 사용된다. 뮤텍스는 하나의 스레드가 크리티컬 섹션에서 실행하는 동안 다른 스레드를 "배제" 하도록 보장해 준다. 따라서 뮤텍스는 크리티컬 섹션에 대해 상호 배제를 보장한다.

Pthreads 표준은 뮤텍스의 특별한 타입인 pthread_mutex_t를 포함하고 있다. pthread_mutex_t 타입의 변수는 사용하기 전에 시스템에 의해 초기화되어야 한다.

```c
int pthread_mutex_init(
      pthread_mutex_t*            mutex_p     /* out  */,
      const pthread_mutexattr_t*  attr_p  /* in   */);
```

두 번째 인수는 사용하지 않기 때문에 NULL을 넘긴다. Pthreads 프로그램에서 뮤텍스의 사용을 종료할 때는 다음을 호출해야 한다.

```c
int pthread_mutex_destroy(pthread_mutex_t* mutex_p /* in/out */);
```

크리티컬 섹션을 액세스하기 위해 스레드는 다음의 함수를 호출한다.

```c
int pthread_mutex_lock(pthread_mutex_t* mutex_p /* in/out */);
```

스레드가 크리티컬 섹션 내부의 코드 실행을 끝냈을 때 다음을 호출한다.

```c
int pthread_mutex_unlock(pthread_mutex_t* mutex_p /* in/out */);
```

pthread_mutex_lock에 대한 호출은 다른 스레드가 크리티컬 섹션에 없을 때까지 스레드를 대기하도록 한다. pthread_mutex_unlock은 호출한 스레드가 크리티컬 섹션의 코드 실행을 완료했음을 시스템에 알려 준다.

## 프로듀서-컨슈머 동기화와 세마포어

비지-웨이팅이 CPU의 리소스를 소비하지만 스레드가 크리티컬 섹션의 코드를 실행하는 순서는 알 수 있다.
뮤텍스를 사용하면 크리티컬 섹션을 실행하는 스레드의 순서는 시스템에 달렸다. 여기서 매트릭스 곱셈의 경우 상호 교환적이지 않기 때문에 뮤텍스 솔루션을 사용하는 것은 문제가 된다.
따라서, POSIX는 크리티컬 섹션에 대한 액세스를 제어하기 위해 semaphore를 제공한다.

세마포어는 unsigned int의 특별한 타입이라고 생각하면 된다. 따라서 세마포어의 값은 0, 1, 2와 같다. 대부분의 경우 세마포어의 값이 0이나 1인 경우만 사용한다. 이러한 세마포어를 바이너리 세마포어라고 한다. 일반적으로 말하면 세마포어의 값이 0일 때는 뮤텍스를 잠갔다(lock)고 하고, 1인 경우는 뮤텍스를 해제(unlock)했다고 한다. 뮤텍스로 바이너리 세마포어를 사용하기 위해서는 처음에는 1로 초기화한다. 보호하려는 크리티컬 섹션 전에, sem_wait 함수의 호출 코드를 둔다. sem_wait를 실행하는 스레드는 세마포어가 0이면 블록한다. 세마포어가 0이 아닌 값이면 세마포어의 값을 하나 감소시키고, 계속 실행한다. 크리티컬 섹션에 있는 코드를 실행한 후에 스레드는 sem_post를 호출하며, 이 함수는 세마포어를 증가시키고 sem_wait에서 대기하는 스레드가 진행을 하게 된다.

세마포어는 열차가 선로를 사용할 때 제어하는 선로 제어 장치의 이름에서 따왔다. 이 장치는 막대기가 아래를 가리키면 접근하는 열차는 계속 진행을 하고, 막대기가 수직이면 접근하는 열차는 멈추고 대기해야 한다. 마찬가로, sem_wait, sem_post는 시그널(아래, 수직)에 해당하고, 진행상황은 세마포어와 같다.

하지만 세마포어는 표준이 아니라서 다음의 헤더를 추가해야한다.

```
#include <semaphore.h>
```

마지막으로 메시지 패싱 문제는 크리티컬 섹션에 포함되지 않았다. 문제는 한 번에 하나의 스레드만이 실행할 수 있는 코드의 블록이라는 것은 아니다. 오히려 my_rank 스레드는 source 스레드가 메시지 생성을 끝낼 때까지 진행하지 않는다. 이러한 타입의 동기화는 스레드가 다른 스레드가 어떤 액션을 수행할 때까지 진행하지 않으며 이런 형태의 동기화를 producer-consumer synchronization 라고 한다.

## 배리어와 조건 변수

스레드를 동기화하는 것은 스레드들이 프로그램의 같은 부분에 있는 경우이다. 동기화의 그런 부분을 barrier라고 하며 어떤 스레드도 모든 스레드가 배리어에 도달하기 전까지는 실행할 수가 없다.

배리어는 여러 가지 어플리케이션에서 사용된다. 멀티스레드 프로그램의 일부분에 대한 타이밍을 맞추려고 한다면 모든 스레드는 같은 순간에 타이밍 코드를 시작해야 한다. 그러고 나서 마지막 스레드가 완료될 때 구한 시간을 출력해야 한다.

이와 같은 배리어를 사용하는 중요한 이유는 디버깅이다. 이미 봤던 것처럼 병렬 프로그램에서는 에러가 언제 발생할지 알기가 매우 어렵다. 물론 프로그램에서 어떤 지점에 도달했다는 것을 알려 주는 메시지를 각 스레드가 출력하게 할 수 있다. 그러나 이런 방법은 출력하는 메시지가 너무 많아진다. 배리어를 사용하면 이런 문제를 해결할 수 있다.

그런데, Pthreads에서 배리어를 제공하지 않기 때문에 직접 구현해야 한다.
비지-웨이팅과 뮤텍스를 활용하는 두 가지 방법과 condition variable이라는 새로운 타입의 Pthreads 객체를 사용한다.

### 비지-웨이팅과 뮤텍스

뮤텍스에 의해 보호되는 공유 카운터를 사용하면 직관적으로 배리어를 구현할 수 있다. 카운터는 모든 스레드가 크리티컬 섹션에 진입했다는 것을 알려 준다. 스레드는 비지-웨이트 루프를 남겨 둘 수 있다.

```c {.line-numbers}
int counter;
int thread_count;
pthread_mutex_t barrier_mutex;
...
void* Thread_work(...);
  ...
  /* barrier */
  pthread_mutex_lock(&barrier_mutex);
  counter++;
  pthread_mutex_unlock(&barrier_mutex);
  while (counter < thread_count);
  ...
```

물론 이 구현은 다른 비지-웨이트 코드가 갖고 있는 같은 문제를 갖고 있다. 스레드가 비지-웨이트 루프에 있을 때 CPU 사이클을 소모하게 되며 코어보다 더 많은 스레드를 실행하면 프로그램의 성능이 심각하게 저하되는 것을 알 수 있다.

다른 문제는 공유 변수 counter이다. 두 번째 배리어를 실행하고 카운트를 다시 사용하려고 할 때 어떤 일 일어날까? 첫 번째 배리어가 완료되고, 카운터는 thread_count 값을 갖게 된다. counter를 리셋하지 않으면 첫 번째 배리어를 사용하는 while 문의 counter < thread_count 는 false 가 되고 배리어는 스레드를 블록하지 않게 된다. 따라서 counter를 0으로 리셋하려는 시도는 거의 모두 실패가 된다. 마지막 스레드가 counter를 리셋하는 루프에 진입한다면 비지-웨이트에 있는 어떤 스레드는 counter == thread_count인 경우를 결코 만나지 못하게 되며 스레드는 계속 비지-웨이트에 있게 된다. 스레드가 배리어 후에 카운터를 리셋하려고 한다면 다른 스레드는 카운터가 리셋되기 전에 두 번째 배리어에 진입하기 때문에 카운터의 증가값을 잃어버리게 된다. 이것은 모든 스레드가 두 번째 비지-웨이트 루프에서 hang되는 원하지 않는 결과를 만들 수 있다. 이 배리어를 사용하려고 하면 배리어의 각 인스턴스를 위한 카운터 변수가 필요하다.

### 조건 변수

Pthreads에서 배리어를 생성하는 좋은 방법은 condition variable을 사용하는 것이다. 조건 변수는 스레드가 특정 이벤트나 condition이 발생할 때까지 실행을 suspend하는 데이터 객체이다. 이벤트나 조건이 발생할 때 다른 스레드는 그 스레드에게 wake up 시그널을 보낸다. 조건 변수는 항상 뮤텍스와 관련이 있다.

```c
lock mutex;
if condition has occurred
  signal thread(s);
else {
  unlock the mutex and block;
  /* Mutex has been relocked when thread has been unblocked.
}
unlock mutex;
```

## 읽기-쓰기 잠금

대규모이거나 공유 데이터 구조에 대한 액세스를 제어할 때 발생하는 문제점에 대해서 살펴보자. 이러한 자료 구조는 간단하게 검색할 수도 있고 스레드에 의해 쉽게 업데이트될 수도 있다. 명시적으로 사용하기 위해 공유 자료 구조는 int형의 정렬된 linked list로 되어 있으며, 관련 오퍼레이션은 Member, Insert, Delete이다.

### 링크드 리스트 함수

-   Member: 노드 탐색
-   Insert: 노드 추가
-   Delete: 노드 삭제

### 멀티스레드 링크드 리스트

다중 스레드는 충돌 없이 메모리 위치에서 동시에 값을 일겅 올 수 있기 때문에 다중 스레드는 동시에 Member를 실행할 수 있다. 한편 Delete와 Insert는 메모리 위치에 쓰는 작업을 한다. 따라서 오퍼레이션이 동시에 실행된다면 문제가 될 가능성이 높다.

이 문제를 해결하기 위해 리스트를 뮤텍스로 감싼다면 리스트 검색 코드가 시리얼하게 바뀐다. 혹은 노드를 뮤텍스로 감싼다면 각기 다른 스레드가 액세스할 수 있지만 데이터가 많이 필요하다.

<!--## 캐시, 캐시 일관성, 그리고 거짓 공유

## 스레드 세이프티-->
